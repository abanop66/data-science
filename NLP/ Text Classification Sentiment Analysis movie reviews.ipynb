{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words('neg/cv000_29416.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[]\n",
    "for category in movie_reviews.categories():\n",
    "    for fid in movie_reviews.fileids(category):\n",
    "        documents.append([movie_reviews.words(fid),category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list=set(stopwords.words('english'))\n",
    "stopwords_list2=[',','.',\"'\",'\"\"','-',')','(',')','!','?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for word in movie_reviews.words():\n",
    "    if word not in stopwords_list:\n",
    "        words.append(word.lower())\n",
    "\n",
    "words_fd=nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 77717),\n",
       " ('.', 65876),\n",
       " (\"'\", 30585),\n",
       " ('\"', 17612),\n",
       " ('-', 15595),\n",
       " (')', 11781),\n",
       " ('(', 11664),\n",
       " ('film', 9517),\n",
       " ('one', 5852),\n",
       " ('movie', 5771)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features=list(words_fd.keys())[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['most', 'people', 'fit', 'into', 'two', 'different', ...], 'pos']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set=[]\n",
    "for (review,category) in documents:\n",
    "    words=list(word for word in review if word not in stopwords_list and word not in stopwords_list2)\n",
    "    features={}\n",
    "    for f in word_features:\n",
    "        features[f] = f in words\n",
    "    features_set.append([features,category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=features_set[:1800]\n",
    "testing_set=features_set[1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(clf,testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  turkey = True              neg : pos    =      8.2 : 1.0\n",
      "                 singers = True              pos : neg    =      6.3 : 1.0\n",
      "               underwood = True              neg : pos    =      5.7 : 1.0\n",
      "                 bronson = True              neg : pos    =      5.7 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.7 : 1.0\n",
      "                 unravel = True              pos : neg    =      5.0 : 1.0\n",
      "                  poorly = True              neg : pos    =      5.0 : 1.0\n",
      "                   awful = True              neg : pos    =      4.8 : 1.0\n",
      "                  sexist = True              neg : pos    =      4.6 : 1.0\n",
      "                 runtime = True              neg : pos    =      4.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
